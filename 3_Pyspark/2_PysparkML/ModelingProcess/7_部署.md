## 1. 预测集
```python

dfs = [spark.table('finance.mls_member_lab_info').withColumn('id', concat_ws('|', array(
    'acct_no', 'member_id', 'id_card', 'email', 'mbl'))).filter("epp_actv_mem_lvl='A1'"),
       spark.table('fdm_dpa.mls_member_base_attr'),
       spark.table('fdm_dpa.mls_member_base_date_info'),
       spark.table('fdm_dpa.mls_member_invest_action'),
       spark.table('fdm_dpa.mls_member_trade_action'),
       spark.table('fdm_dpa.mls_member_visit_action'),
       spark.table('fdm_dpa.mls_member_value_attr').filter(
           "is_bof_prch = 'N' and is_fin_user = 'N' and eg_mem_lvl in ('161000000130', '161000000140')")]


df = dfs[0]
for _df in dfs[1:]:
    colName = list(set(_df.columns).intersection(df.columns))
    colName.remove('acct_no')
    df = df.join(_df.drop(*colName), 'acct_no') # 每个_df都保留acct_no

colName = spark.table('fbidm.yuanjie_deploy_features_20180108').columns
colName.remove('acct_no')
colName.remove('label')

df = df.select('id', *colName)
df.write.saveAsTable('fbidm.yuanjie_deploy_data_20180108', mode='overwrite')

```

## 2. 预处理
```python

from pyspark.ml import PipelineModel
from pyspark.ml.classification import RandomForestClassificationModel

deploy_date = '20180108'
# 获取字段类型
df = spark.table('fbidm.yuanjie_deploy_features_%s' % deploy_date)
numColName = [i for i, j in df.dtypes if j == 'float']

df = spark.table('fbidm.yuanjie_deploy_data_%s' % deploy_date)
for i in numColName:
    df = df.withColumn(i, col(i).astype(FloatType()))

numColName = ['debt_st',
              'is_mi_fan',
              'is_htc_fan',
              'is_4g',
              'fin_rgst_drtn',
              'cfc_open_drtn',
              'commute_vst_lvl',
              'weekend_vst_lvl',
              'cfc_amt',
              'mgt_store',
              'gds_cgy_love',
              'is_apple_fan',
              'app_hold',
              'is_lenovo_fan',
              'cfc_tml_love',
              'rest_tm_vst_lvl',
              'is_myhz_buyer',
              'auth_type',
              'is_sony_fan',
              'work_dt_vst_lvl',
              'fin_lifecycle',
              'lifecycle',
              'is_3c_buyer',
              'chp_tml_love',
              'work_tm_vst_lvl',
              'is_myhz_buyer_offline',
              'is_nokia_fan',
              'identy',
              'value_lvl',
              'loyal_lvl',
              'is_other_buyer_offline',
              'is_other_buyer',
              'mgt_org',
              'loyalty_level',
              'chn_love',
              'cfc_pay_1st_drtn',
              'epp_non_actv_mem_lvl',
              'eqmt_num',
              'work_life',
              'chnel_cnt',
              'bind_card_num',
              'first_epp_bag_drtn',
              'is_samsung_fan',
              'pay_amt_d',
              'is_oppo_fan',
              'is_huwei_fan',
              'epp_actv_lvl_mon',
              'cfc_rgst_drtn',
              'income',
              'first_buy_goods_type',
              'epp_balance',
              'first_epp_pay_drtn',
              'plsa_customer_src',
              'epp_member_lvl',
              'mem_sts',
              'night_vst_lvl',
              'is_zte_fan',
              'age_type',
              'eg_mem_lvl',
              'epp_lifecycle',
              'actv_rfr_on']
numColName = [i for i in df.columns if i in numColName]

df = df.fillna(-999, numColName).fillna(0).fillna('_NA')

vector_assembler_model = PipelineModel.load('/user/fbidm/modelresult/vector_assembler_%s.model' % deploy_date)
rf_model = RandomForestClassificationModel.load('/user/fbidm/modelresult/model_%s.model' % deploy_date)

df = vector_assembler_model.transform(df).select('id', 'features')

get_prob = udf(lambda x: float(x.array[1]), FloatType())
_split = udf(lambda x: x.split('|'), ArrayType(StringType()))

df = rf_model.transform(df).select(_split('id')[0].name('acct_no'),
                                   _split('id')[1].name('member_id'),
                                   _split('id')[2].name('id_card'),
                                   _split('id')[3].name('email'),
                                   _split('id')[4].name('mbl'),
                                   get_prob('probability').astype('score'))

df.write.saveAsTable('fbidm.yuanjie_deploy_result_%s' % deploy_date, mode='overwrite')
```
